# 字典

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190314145848291.jpg)



字典是基于哈希表实现的，通过上图我们可以看出字典包含了 2 个哈希表，还有一些其他属性，比如 `rehashindex`，`type` 等。

为什么字典使用 2 个哈希表作为底层实现呢？

原因是与 rehash 的时候会用到，使用2个hash表，就可以使用复制-移动算法，类似 jvm里 有2个eden区

## 哈希表

Redis使用哈希表来实现字典结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190314145831191.jpg)



### 一、哈希表dict.h/dictht

```c++
/**
 * 哈希表
 */
typedef struct dictht {
    // 哈希表节点指针数组（俗称桶，bucket）
    dictEntry **table;
    // 指针数组的大小
    unsigned long size;
    // 指针数组的长度掩码，用于计算索引值,大小永远为 size - 1
    unsigned long sizemask;
    // 哈希表现有的节点数量
    unsigned long used;
} dictht;
```



### 二、表节点 dictEntry

```c++
/**
 * 哈希表节点
 */
typedef struct dictEntry {
    // 键
    void *key;
    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;
    // 链往后继节点
    struct dictEntry *next;
} dictEntry;
```



### 三、hash算法

- 解决键冲突

  链式寻址法，通过next指针，往后追加呗

### 四、rehash

- 负载因子

  - 当哈希表中键值对的数量达到哈希表容量的 0.75 倍时就需要对哈希表进行扩容

  Redis 哈希表的负载因子通过下面的公式计算：

  ```c++
  	# 负载因子 = 哈希表已保存节点数量 / 哈希表大小
  	load_factor = ht[0].used / ht[0].size
  ```

- 渐进式hash

  其实 rehash 并不是一次性，集中式的完成的，而是分多次，渐进式完成的。原因是 Redis 的字典字典有可能存储上百万个键值对，如果一次性完成的话，那么 Redis 可能会在一段时间内停止服务，为了保证 Redis 的高性能，这么做肯定是不允许的。

  - rehashidx值表示rehash的状态
    - -1代表没在rehash
    - 0表示rehash开始
    - \>= 0代表rehash中, 以及完成的数组元素的个数比如0 ,3, 10这样的值
    - 如果值==size字段 - 1(数组长度)，代表rehash结束，随后会将idx设置回-1



